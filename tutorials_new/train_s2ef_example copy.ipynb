{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SchNet S2EF training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to demonstrate some of the basics of the Open Catalyst Project's (OCP) codebase and data. In this example, we will train a schnet model for predicting the energy and forces of a given structure (S2EF task). First, ensure you have installed the OCP ocp repo and all the dependencies according to the [README](https://github.com/Open-Catalyst-Project/ocp/blob/master/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: This notebook is for tutorial purposes, it is unlikely it will be practical to train baseline models on our larger datasets using this format. As a next step, we recommend trying the command line examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from ocpmodels.trainers import ForcesTrainer\n",
    "from ocpmodels import models\n",
    "from ocpmodels.common import logger\n",
    "from ocpmodels.common.utils import setup_logging\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# a simple sanity check that a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The essential steps for training an OCP model\n",
    "\n",
    "1) Download data\n",
    "\n",
    "2) Preprocess data (if necessary)\n",
    "\n",
    "3) Define or load a configuration (config), which includes the following\n",
    "   \n",
    "   - task\n",
    "   - model\n",
    "   - optimizer\n",
    "   - dataset\n",
    "   - trainer\n",
    "\n",
    "4) Train\n",
    "\n",
    "5) Depending on the model/task there might be intermediate relaxation step\n",
    "\n",
    "6) Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This examples uses the LMDB generated from the following [tutorial](http://laikapack.cheme.cmu.edu/notebook/open-catalyst-project/mshuaibi/notebooks/projects/ocp/docs/source/tutorials/lmdb_dataset_creation.ipynb). Please run that notebook before moving on. Alternatively, if you have other LMDBs available you may specify that instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to your local lmdb directory\n",
    "train_src = \"s2ef\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will explicitly define the config; however, a set of default config files exists in the config folder of this repository. Default config yaml files can easily be loaded with the `build_config` util (found in `ocp/ocpmodels/common/utils.py`). Loading a yaml config is preferrable when launching jobs from the command line. We have included our best models' config files [here](https://github.com/Open-Catalyst-Project/ocp/tree/master/configs/s2ef)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp: false\n",
      "cmd:\n",
      "  checkpoint_dir: ./checkpoints/2023-04-19-21-43-28-SchNet-example\n",
      "  commit: a8ac36d\n",
      "  identifier: SchNet-example\n",
      "  logs_dir: ./logs/tensorboard/2023-04-19-21-43-28-SchNet-example\n",
      "  print_every: 5\n",
      "  results_dir: ./results/2023-04-19-21-43-28-SchNet-example\n",
      "  seed: 0\n",
      "  timestamp_id: 2023-04-19-21-43-28-SchNet-example\n",
      "dataset:\n",
      "  normalize_labels: false\n",
      "  src: s2ef\n",
      "gpus: 0\n",
      "logger: tensorboard\n",
      "model: schnet\n",
      "model_attributes:\n",
      "  cutoff: 6.0\n",
      "  hidden_channels: 1024\n",
      "  num_filters: 256\n",
      "  num_gaussians: 200\n",
      "  num_interactions: 3\n",
      "noddp: false\n",
      "optim:\n",
      "  batch_size: 16\n",
      "  eval_batch_size: 8\n",
      "  factor: 0.8\n",
      "  force_coefficient: 100\n",
      "  lr_initial: 0.0001\n",
      "  max_epochs: 1\n",
      "  mode: min\n",
      "  num_workers: 8\n",
      "  patience: 3\n",
      "  scheduler: ReduceLROnPlateau\n",
      "slurm: {}\n",
      "task:\n",
      "  dataset: trajectory_lmdb\n",
      "  description: Regressing to energies and forces for DFT trajectories from OCP\n",
      "  eval_on_free_atoms: true\n",
      "  grad_input: atomic forces\n",
      "  labels:\n",
      "  - potential energy\n",
      "  metric: mae\n",
      "  train_on_free_atoms: true\n",
      "  type: regression\n",
      "test_dataset:\n",
      "  src: s2ef\n",
      "trainer: forces\n",
      "val_dataset:\n",
      "  src: s2ef\n",
      "\n",
      "2023-04-19 21:43:33 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2023-04-19 21:43:33 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2023-04-19 21:43:33 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2023-04-19 21:43:33 (INFO): Loading dataset: trajectory_lmdb\n",
      "2023-04-19 21:43:33 (INFO): Loading model: schnet\n",
      "2023-04-19 21:43:33 (INFO): Loaded SchNetWrap with 5704193 parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwbai/miniconda3/envs/ocp-models/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "2023-04-19 21:43:33 (WARNING): Model gradient logging to tensorboard not yet supported.\n"
     ]
    }
   ],
   "source": [
    "# **Task**\n",
    "task = {\n",
    "    'dataset': 'trajectory_lmdb', # dataset used for the S2EF task\n",
    "    'description': 'Regressing to energies and forces for DFT trajectories from OCP',\n",
    "    'type': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'labels': ['potential energy'],\n",
    "    'grad_input': 'atomic forces',\n",
    "    'train_on_free_atoms': True,\n",
    "    'eval_on_free_atoms': True\n",
    "}\n",
    "# **Model** - SchNet for this example\n",
    "model = {\n",
    "    'name': 'schnet',\n",
    "    'hidden_channels': 1024, # if training is too slow for example purposes reduce the number of hidden channels\n",
    "    'num_filters': 256,\n",
    "    'num_interactions': 3,\n",
    "    'num_gaussians': 200,\n",
    "    'cutoff': 6.0\n",
    "}\n",
    "# **Optimizer** \n",
    "optimizer = {\n",
    "    'batch_size': 16, # if hitting GPU memory issues, lower this\n",
    "    'eval_batch_size': 8,\n",
    "    'num_workers': 8,\n",
    "    'lr_initial': 0.0001,\n",
    "    'scheduler': \"ReduceLROnPlateau\",\n",
    "    'mode': \"min\",\n",
    "    'factor': 0.8,\n",
    "    'patience': 3,\n",
    "    'max_epochs': 80,\n",
    "    'max_epochs': 1, # used for demonstration purposes\n",
    "    'force_coefficient': 100,\n",
    "}\n",
    "# **Dataset**\n",
    "# For simplicity, `train_src` is used for all the train/val/test sets. Feel free to update with the actual S2EF val and test sets, but it does require additional downloads and preprocessing. If you desire to normalize your targets, `normalize_labels` must be set to `True` and corresponding `mean` and `stds` need to be specified. These values have been precomputed for you and can be found in any of the [`base.yml`](https://github.com/Open-Catalyst-Project/ocp/blob/master/configs/s2ef/20M/base.yml#L5-L9) config files. -->\n",
    "dataset = [\n",
    "{'src': train_src, 'normalize_labels': False}, # train set \n",
    "{'src': train_src}, # val set (optional)\n",
    "{'src': train_src} # test set (optional - writes predictions to disk)\n",
    "]\n",
    "# **Trainer**\n",
    "# Use the `ForcesTrainer` for the S2EF and IS2RS tasks, and the `EnergyTrainer` for the IS2RE task  -->\n",
    "trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"SchNet-example\",\n",
    "    run_dir=\"./\", # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=False, # if True, do not save checkpoint, logs, or results\n",
    "    # is_vis=False,\n",
    "    print_every=5,\n",
    "    seed=0, # random seed to use\n",
    "    logger=\"tensorboard\", # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False, # use PyTorch Automatic Mixed Precision (faster training and less memory usage)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCPDataParallel(\n",
      "  (module): SchNetWrap(hidden_channels=1024, num_filters=256, num_interactions=3, num_gaussians=200, cutoff=6.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(trainer.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19 21:43:39 (INFO): forcesx_mae: 3.20e-01, forcesy_mae: 3.20e-01, forcesz_mae: 3.59e+00, forces_mae: 1.41e+00, forces_cos: -3.49e-03, forces_magnitude: 3.93e+00, energy_mae: 7.04e+00, energy_force_within_threshold: 0.00e+00, loss: 4.30e+02, lr: 1.00e-04, epoch: 7.94e-02, step: 5.00e+00\n",
      "2023-04-19 21:43:44 (INFO): forcesx_mae: 1.61e-01, forcesy_mae: 1.61e-01, forcesz_mae: 2.13e+00, forces_mae: 8.16e-01, forces_cos: -4.33e-03, forces_magnitude: 2.25e+00, energy_mae: 1.73e+00, energy_force_within_threshold: 0.00e+00, loss: 2.47e+02, lr: 1.00e-04, epoch: 1.59e-01, step: 1.00e+01\n",
      "2023-04-19 21:43:48 (INFO): forcesx_mae: 7.80e-02, forcesy_mae: 7.78e-02, forcesz_mae: 1.45e+00, forces_mae: 5.34e-01, forces_cos: -7.80e-03, forces_magnitude: 1.50e+00, energy_mae: 1.18e+00, energy_force_within_threshold: 0.00e+00, loss: 1.62e+02, lr: 1.00e-04, epoch: 2.38e-01, step: 1.50e+01\n",
      "2023-04-19 21:43:51 (INFO): forcesx_mae: 7.42e-02, forcesy_mae: 7.41e-02, forcesz_mae: 8.12e-01, forces_mae: 3.20e-01, forces_cos: -2.49e-04, forces_magnitude: 8.87e-01, energy_mae: 3.23e-01, energy_force_within_threshold: 0.00e+00, loss: 9.64e+01, lr: 1.00e-04, epoch: 3.17e-01, step: 2.00e+01\n",
      "2023-04-19 21:43:55 (INFO): forcesx_mae: 3.82e-02, forcesy_mae: 3.82e-02, forcesz_mae: 5.54e-01, forces_mae: 2.10e-01, forces_cos: 1.49e-02, forces_magnitude: 5.91e-01, energy_mae: 3.70e-01, energy_force_within_threshold: 0.00e+00, loss: 6.34e+01, lr: 1.00e-04, epoch: 3.97e-01, step: 2.50e+01\n",
      "2023-04-19 21:43:59 (INFO): forcesx_mae: 1.76e-02, forcesy_mae: 1.76e-02, forcesz_mae: 3.69e-01, forces_mae: 1.35e-01, forces_cos: 6.95e-03, forces_magnitude: 3.80e-01, energy_mae: 1.98e-01, energy_force_within_threshold: 0.00e+00, loss: 4.06e+01, lr: 1.00e-04, epoch: 4.76e-01, step: 3.00e+01\n",
      "2023-04-19 21:44:02 (INFO): forcesx_mae: 6.26e-03, forcesy_mae: 6.20e-03, forcesz_mae: 2.46e-01, forces_mae: 8.62e-02, forces_cos: -1.06e-02, forces_magnitude: 2.49e-01, energy_mae: 1.91e-01, energy_force_within_threshold: 0.00e+00, loss: 2.61e+01, lr: 1.00e-04, epoch: 5.56e-01, step: 3.50e+01\n",
      "2023-04-19 21:44:06 (INFO): forcesx_mae: 4.85e-03, forcesy_mae: 4.85e-03, forcesz_mae: 2.27e-01, forces_mae: 7.90e-02, forces_cos: -7.20e-03, forces_magnitude: 2.28e-01, energy_mae: 4.23e-01, energy_force_within_threshold: 0.00e+00, loss: 2.41e+01, lr: 1.00e-04, epoch: 6.35e-01, step: 4.00e+01\n",
      "2023-04-19 21:44:10 (INFO): forcesx_mae: 2.36e-02, forcesy_mae: 2.36e-02, forcesz_mae: 2.43e-01, forces_mae: 9.66e-02, forces_cos: -2.93e-03, forces_magnitude: 2.74e-01, energy_mae: 7.34e-01, energy_force_within_threshold: 0.00e+00, loss: 2.97e+01, lr: 1.00e-04, epoch: 7.14e-01, step: 4.50e+01\n",
      "2023-04-19 21:44:13 (INFO): forcesx_mae: 1.34e-02, forcesy_mae: 1.34e-02, forcesz_mae: 2.36e-01, forces_mae: 8.77e-02, forces_cos: 9.18e-03, forces_magnitude: 2.49e-01, energy_mae: 6.95e-01, energy_force_within_threshold: 0.00e+00, loss: 2.70e+01, lr: 1.00e-04, epoch: 7.94e-01, step: 5.00e+01\n",
      "2023-04-19 21:44:16 (INFO): forcesx_mae: 1.25e-02, forcesy_mae: 1.25e-02, forcesz_mae: 1.65e-01, forces_mae: 6.33e-02, forces_cos: 3.22e-03, forces_magnitude: 1.76e-01, energy_mae: 1.45e+00, energy_force_within_threshold: 0.00e+00, loss: 2.05e+01, lr: 1.00e-04, epoch: 8.73e-01, step: 5.50e+01\n",
      "2023-04-19 21:44:20 (INFO): forcesx_mae: 2.84e-02, forcesy_mae: 2.84e-02, forcesz_mae: 2.06e-01, forces_mae: 8.76e-02, forces_cos: -2.51e-02, forces_magnitude: 2.35e-01, energy_mae: 6.06e-01, energy_force_within_threshold: 0.00e+00, loss: 2.69e+01, lr: 1.00e-04, epoch: 9.52e-01, step: 6.00e+01\n",
      "2023-04-19 21:44:23 (INFO): Evaluating on val.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "device 0: 100%|██████████| 126/126 [00:21<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19 21:44:45 (INFO): forcesx_mae: 0.0006, forcesy_mae: 0.0005, forcesz_mae: 0.2729, forces_mae: 0.0913, forces_cos: 0.0031, forces_magnitude: 0.2725, energy_mae: 0.3773, energy_force_within_threshold: 0.0000, loss: 27.7826, epoch: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19 21:44:45 (INFO): Predicting on test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "device 0: 100%|██████████| 126/126 [00:18<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19 21:45:04 (INFO): Writing results to ./results/2023-04-19-21-43-28-SchNet-example/s2ef_predictions.npz\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint\n",
    "Once training has completed a `Trainer` class, by default, is loaded with the best checkpoint as determined by training or validation (if available) metrics. To load a `Trainer` class directly with a pretrained model, specify the `checkpoint_path` as defined by your previously trained model (`checkpoint_dir`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoints/2023-04-19-21-43-28-SchNet-example/checkpoint.pt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(trainer.config[\"cmd\"][\"checkpoint_dir\"], \"checkpoint.pt\")\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp: false\n",
      "cmd:\n",
      "  checkpoint_dir: ./checkpoints/2023-04-19-21-45-36-SchNet-example\n",
      "  commit: a8ac36d\n",
      "  identifier: SchNet-example\n",
      "  logs_dir: ./logs/tensorboard/2023-04-19-21-45-36-SchNet-example\n",
      "  print_every: 10\n",
      "  results_dir: ./results/2023-04-19-21-45-36-SchNet-example\n",
      "  seed: 0\n",
      "  timestamp_id: 2023-04-19-21-45-36-SchNet-example\n",
      "dataset:\n",
      "  normalize_labels: false\n",
      "  src: s2ef\n",
      "gpus: 0\n",
      "logger: tensorboard\n",
      "model: schnet\n",
      "model_attributes:\n",
      "  cutoff: 6.0\n",
      "  hidden_channels: 1024\n",
      "  num_filters: 256\n",
      "  num_gaussians: 200\n",
      "  num_interactions: 3\n",
      "noddp: false\n",
      "optim:\n",
      "  batch_size: 16\n",
      "  eval_batch_size: 8\n",
      "  factor: 0.8\n",
      "  force_coefficient: 100\n",
      "  lr_initial: 0.0001\n",
      "  max_epochs: 1\n",
      "  mode: min\n",
      "  num_workers: 8\n",
      "  patience: 3\n",
      "  scheduler: ReduceLROnPlateau\n",
      "slurm: {}\n",
      "task:\n",
      "  dataset: trajectory_lmdb\n",
      "  description: Regressing to energies and forces for DFT trajectories from OCP\n",
      "  eval_on_free_atoms: true\n",
      "  grad_input: atomic forces\n",
      "  labels:\n",
      "  - potential energy\n",
      "  metric: mae\n",
      "  train_on_free_atoms: true\n",
      "  type: regression\n",
      "test_dataset:\n",
      "  src: s2ef\n",
      "trainer: forces\n",
      "val_dataset:\n",
      "  src: s2ef\n",
      "\n",
      "2023-04-19 21:45:04 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2023-04-19 21:45:04 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2023-04-19 21:45:04 (INFO): Batch balancing is disabled for single GPU training.\n",
      "2023-04-19 21:45:04 (INFO): Loading dataset: trajectory_lmdb\n",
      "2023-04-19 21:45:04 (INFO): Loading model: schnet\n",
      "2023-04-19 21:45:04 (INFO): Loaded SchNetWrap with 5704193 parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwbai/miniconda3/envs/ocp-models/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "2023-04-19 21:45:04 (WARNING): Model gradient logging to tensorboard not yet supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19 21:45:04 (INFO): Loading checkpoint from: ./checkpoints/2023-04-19-21-43-28-SchNet-example/checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "model = {\n",
    "    'name': 'schnet',\n",
    "    'hidden_channels': 1024, # if training is too slow for example purposes reduce the number of hidden channels\n",
    "    'num_filters': 256,\n",
    "    'num_interactions': 3,\n",
    "    'num_gaussians': 200,\n",
    "    'cutoff': 6.0\n",
    "}\n",
    "\n",
    "pretrained_trainer = ForcesTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"SchNet-example\",\n",
    "    run_dir=\"./\", # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=False, # if True, do not save checkpoint, logs, or results\n",
    "    # is_vis=False,\n",
    "    print_every=10,\n",
    "    seed=0, # random seed to use\n",
    "    logger=\"tensorboard\", # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=False, # use PyTorch Automatic Mixed Precision (faster training and less memory usage)\n",
    ")\n",
    "\n",
    "pretrained_trainer.load_checkpoint(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a test has been provided in your config, predictions are generated and written to disk automatically upon training completion. Otherwise, to make predictions on unseen data a `torch.utils.data` DataLoader object must be constructed. Here we reference our test set to make predictions on. Predictions are saved in `{results_file}.npz` in your `results_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19 21:45:05 (INFO): Predicting on test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "device 0: 100%|██████████| 126/126 [00:20<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19 21:45:25 (INFO): Writing results to ./results/2023-04-19-21-45-36-SchNet-example/s2ef_s2ef_results.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the existing test_loader\n",
    "predictions = pretrained_trainer.predict(pretrained_trainer.test_loader, results_file=\"s2ef_results\", disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = predictions[\"energy\"]\n",
    "forces = predictions[\"forces\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
